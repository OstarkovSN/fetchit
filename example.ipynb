{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightRAG usage example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import base64\n",
    "from getpass import getpass\n",
    "\n",
    "import nest_asyncio\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from langchain_openai import ChatOpenAI\n",
    "from huggingface_hub import notebook_login, login\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm import (\n",
    "    hf_embedding,\n",
    "    openai_complete_if_cache,\n",
    "\n",
    ")\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "\n",
    "from utils.config import Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up LightRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config loading & workdir creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"secrets.json\"):\n",
    "    secrets = {\n",
    "        \"samba_nova_api_key\": [\n",
    "            getpass(prompt=\"Your SambaNova API key (input hiddden): \")\n",
    "        ],\n",
    "        \"huggingface_token\": [\n",
    "            getpass(prompt=\"Your Hugging Face token (input hidden): \")\n",
    "        ],\n",
    "    }\n",
    "    with open(\"secrets.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(secrets, f, ensure_ascii=False, indent=4)\n",
    "if not os.path.exists(\"config.json\"):\n",
    "    with open(\"config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({}, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "config = Configuration(\"config.json\")\n",
    "\n",
    "try:\n",
    "    token = config[\"huggingface_token\"]\n",
    "    assert isinstance(token, str), \"Invalid token type encountered somehow\"\n",
    "    login(token)\n",
    "    print(\"Login successful!\")\n",
    "except KeyError:\n",
    "    notebook_login()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "WORKING_DIR = config[\"processed/lightrag\"]\n",
    "DATA_PATH = config[\"raw/\"]\n",
    "assert isinstance(\n",
    "    WORKING_DIR, str\n",
    "), f\"WORKING_DIR should be a string but is {type(WORKING_DIR)}\"\n",
    "assert isinstance(\n",
    "    DATA_PATH, str\n",
    "), f\"DATA_PATH should be a string but is {type(DATA_PATH)}\"\n",
    "empty = not os.path.exists(\"lightrag\") or not os.listdir(\"lightrag\")\n",
    "os.makedirs(WORKING_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightRAG init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Logger initialized for working directory: data/processed/lightrag\n",
      "INFO:lightrag:Load KV llm_response_cache with 0 data\n",
      "INFO:lightrag:Load KV full_docs with 0 data\n",
      "INFO:lightrag:Load KV text_chunks with 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 384, 'metric': 'cosine', 'storage_file': 'data/processed/lightrag/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 384, 'metric': 'cosine', 'storage_file': 'data/processed/lightrag/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 384, 'metric': 'cosine', 'storage_file': 'data/processed/lightrag/vdb_chunks.json'} 0 data\n"
     ]
    }
   ],
   "source": [
    "async def llm_model_func(\n",
    "    prompt, system_prompt=None, history_messages=[], sleep_time=0, **kwargs\n",
    ") -> str:\n",
    "    return await openai_complete_if_cache(\n",
    "        \"Meta-Llama-3.1-405B-Instruct\",\n",
    "        prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        history_messages=history_messages,\n",
    "        api_key=config['samba_nova_api_key'],\n",
    "        base_url=\"https://api.sambanova.ai/v1\",\n",
    "        sleep_time=sleep_time,\n",
    "        **config['openai_complete_if_cache_kwargs']\n",
    "    )\n",
    "\n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=WORKING_DIR,\n",
    "    llm_model_func=llm_model_func,\n",
    "    embedding_func=EmbeddingFunc(\n",
    "        embedding_dim=384,\n",
    "        max_token_size=5000,\n",
    "        func=lambda texts: hf_embedding(\n",
    "            texts,\n",
    "            tokenizer=AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"),\n",
    "            embed_model=AutoModel.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        )\n",
    "    ),\n",
    "    **config['rag_kwargs']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c7ea54a8e14ee9bcc14aca717dc478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunking documents:   0%|          | 0/2 [00:00<?, ?doc/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content from file: data/raw/Росконгресс_Рынок_промышленных_роботов_в_мире_и_России_2024_16_стр.pdf...done!\n",
      "Extracting content from file: data/raw/СП_496_1325800_2020_Основания_и_фундаменты_зданий_и_сооружений.docx...done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60956414f45442bbc64905514b1fdea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2900d355714366bf94eb83d0f2c504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting entities from chunks:   0%|          | 0/217 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 148 entities(duplicated), 68 relations(duplicated)\r"
     ]
    }
   ],
   "source": [
    "pdf_path = config['raw/Росконгресс_Рынок_промышленных_роботов_в_мире_и_России_2024_16_стр.pdf']\n",
    "docx_path = config['raw/СП_496_1325800_2020_Основания_и_фундаменты_зданий_и_сооружений.docx']\n",
    "logging.disable()\n",
    "rag.insert([pdf_path, docx_path], config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single = ChatOpenAI(api_key=config['samba_nova_api_key'],\n",
    "                base_url=\"https://api.sambanova.ai/v1\",\n",
    "                model=\"Meta-Llama-3.1-405B-Instruct\",\n",
    "                streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"В каких случаях применяют повышение кровли ММГ до уровня подошвы насыпи для производства земляных работ при устройстве оснований и фундаментов на ММГ\"\n",
    "print('\\n## RAG-Answer\\n')\n",
    "print(rag.query(query, param=QueryParam(mode=\"local\",\n",
    "                                                                            max_token_for_global_context=1650,\n",
    "                                                                            max_token_for_local_context=1650,\n",
    "                                                                            max_token_for_text_unit=1450)))\n",
    "print('\\n## -Llama-405B-Answer\\n')\n",
    "\n",
    "print(single.invoke(query).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision LLM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision = ChatOpenAI(api_key=config['samba_nova_api_key'],\n",
    "                base_url=\"https://api.sambanova.ai/v1\",\n",
    "                model=\"Llama-3.2-11B-Vision-Instruct\",\n",
    "                streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = config['raw/image.jpg']\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    encoded = base64.b64encode(image_file.read())\n",
    "    url = f'data:image/jpeg;base64,{encoded.decode(\"utf-8\")}'\n",
    "print(vision.invoke([{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"What do you see in this image\"},{\"type\":\"image_url\",\"image_url\":{\"url\":url}}]}]).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the GraphML file\n",
    "G = nx.read_graphml(f'{WORKING_DIR}/graph_chunk_entity_relation.graphml')\n",
    "\n",
    "# Create a Pyvis network\n",
    "net = Network(notebook=True)\n",
    "\n",
    "# Convert NetworkX graph to Pyvis network\n",
    "net.from_nx(G)\n",
    "\n",
    "# Save and display the network\n",
    "net.save_graph(f'{WORKING_DIR}/knowledge_graph.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
